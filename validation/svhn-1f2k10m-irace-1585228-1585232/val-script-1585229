#!/bin/bash
#SBATCH --time=1-0:00
#SBATCH --cpus-per-task=1
#SBATCH --mem-per-cpu=16G
#SBATCH --array=0-3
#SBATCH --job-name=svhn-1f2k10m-irace-val
#SBATCH --output=validation/svhn-1f2k10m-irace-1585228-1585232/svhn-1f2k10m-irace-1585229-val-%A-%a

CONFIGS=("341  --dataset svhn --job_id 1585229 --cutoff 10 --metafolds 1 --task classification --sparse False --f_eng1 Selection --f_eng2 none --pre_scaling False --selection SelectFromModel --sel_model RandomForest --sel_threshold median --scaling True --algorithm MLP --solver adam --alpha -3.9632 --learning_rate_init -1.5403 --hidden_layers 1 --neurons1 419 --activation relu"
"345  --dataset svhn --job_id 1585229 --cutoff 10 --metafolds 1 --task classification --sparse False --f_eng1 Selection --f_eng2 none --pre_scaling False --selection SelectFromModel --sel_model RandomForest --sel_threshold mean --scaling True --algorithm KNeighbors --n_neighbors 15 --weights distance"
"354  --dataset svhn --job_id 1585229 --cutoff 10 --metafolds 1 --task classification --sparse False --f_eng1 Selection --f_eng2 none --pre_scaling False --selection SelectFromModel --sel_model RandomForest --sel_threshold median --scaling True --algorithm MLP --solver adam --alpha -4.4211 --learning_rate_init -1.756 --hidden_layers 1 --neurons1 415 --activation relu"
"363  --dataset svhn --job_id 1585229 --cutoff 10 --metafolds 1 --task classification --sparse False --f_eng1 Selection --f_eng2 none --pre_scaling False --selection SelectFromModel --sel_model RandomForest --sel_threshold median --scaling True --algorithm MLP --solver adam --alpha -4.9301 --learning_rate_init -2.8394 --hidden_layers 1 --neurons1 248 --activation relu"
)

srun python /home/cemvieira/isklearn/svhn/validation.py ${CONFIGS[$SLURM_ARRAY_TASK_ID]}
